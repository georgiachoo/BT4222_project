{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import loguniform\n",
    "from sklearn import metrics, svm\n",
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.read_excel('./X_train_encoded.xlsx')\n",
    "x_val_df = pd.read_excel('./X_val_encoded.xlsx')\n",
    "x_test_df = pd.read_excel('./X_test_encoded.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.read_excel('./Y_train.xlsx')\n",
    "y_train = y_train_df.values.ravel()\n",
    "y_val_df = pd.read_excel('./Y_val.xlsx')\n",
    "y_val = y_val_df.values.ravel()\n",
    "y_test_df = pd.read_excel('./Y_test.xlsx')\n",
    "y_test = y_test_df.values.ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.05, eval_metric=None,\n",
      "              feature_types=None, gamma=5, gpu_id=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
      "              max_leaves=None, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=250, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, ...)\n",
      "train f1 score: 0.644545991653195\n",
      "train precision: 0.6451200017402402\n",
      "train recall: 0.6448214285714285\n"
     ]
    }
   ],
   "source": [
    "#Randomized search for xgboost parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': range(50, 400, 50),\n",
    "    'min_child_weight': range(1, 10, 1),\n",
    "    'max_depth': range(3, 10, 1),\n",
    "    'eta': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "    'colsample_bytree': np.arange(0.5, 1, 0.1),\n",
    "    'subsample': np.arange(0.5, 1, 0.1),\n",
    "    'gamma': [1, 3, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "search_xgb = RandomizedSearchCV(XGBClassifier(objective='binary:logistic', seed=105), param_distributions=xgb_params, n_iter=100, \n",
    "                                scoring='f1_weighted', n_jobs=-1, verbose=4, random_state=105, refit=True)\n",
    "\n",
    "search_xgb.fit(x_train_df, y_train)\n",
    "xgb = search_xgb.best_estimator_\n",
    "print(f'Best model: {xgb}')\n",
    "\n",
    "y_pred_train_xgb = xgb.predict(x_train_df)\n",
    "xgb_train_f1 = metrics.f1_score(y_train, y_pred_train_xgb, average=\"weighted\")\n",
    "xgb_train_precision = metrics.precision_score(y_train, y_pred_train_xgb, average=\"weighted\")\n",
    "xgb_train_recall = metrics.recall_score(y_train, y_pred_train_xgb, average=\"weighted\")\n",
    "print(f'train f1 score: {xgb_train_f1}')\n",
    "print(f'train precision: {xgb_train_precision}')\n",
    "print(f'train recall: {xgb_train_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation f1 score: 0.6244221119975949\n",
      "validation precision: 0.6261525243706334\n",
      "validation recall: 0.6248333333333334\n"
     ]
    }
   ],
   "source": [
    "#Implement best model on validate set\n",
    "xgb.fit(x_train_df, y_train)\n",
    "y_pred_xgb = xgb.predict(x_val_df)\n",
    "\n",
    "xgb_validate_f1 = metrics.f1_score(y_val, y_pred_xgb, average=\"weighted\")\n",
    "xgb_validate_precision = metrics.precision_score(y_val, y_pred_xgb, average=\"weighted\")\n",
    "xgb_validate_recall = metrics.recall_score(y_val, y_pred_xgb, average=\"weighted\")\n",
    "print(f'validation f1 score: {xgb_validate_f1}')\n",
    "print(f'validation precision: {xgb_validate_precision}')\n",
    "print(f'validation recall: {xgb_validate_recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END C=100, penalty=None, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=None, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=None, solver=newton-cg;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=None, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=None, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END .C=100, penalty=None, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END .C=100, penalty=None, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END .C=100, penalty=None, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END .C=100, penalty=None, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END .C=100, penalty=None, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, penalty=None, solver=sag;, score=0.605 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, penalty=None, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, penalty=None, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ...C=100, penalty=None, solver=sag;, score=0.606 total time=   0.2s\n",
      "[CV 5/5] END ...C=100, penalty=None, solver=sag;, score=0.599 total time=   0.2s\n",
      "[CV 1/5] END C=100, penalty=l2, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=newton-cg;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, penalty=l2, solver=sag;, score=0.605 total time=   0.5s\n",
      "[CV 2/5] END .....C=100, penalty=l2, solver=sag;, score=0.601 total time=   0.6s\n",
      "[CV 3/5] END .....C=100, penalty=l2, solver=sag;, score=0.609 total time=   0.5s\n",
      "[CV 4/5] END .....C=100, penalty=l2, solver=sag;, score=0.606 total time=   0.5s\n",
      "[CV 5/5] END .....C=100, penalty=l2, solver=sag;, score=0.599 total time=   0.5s\n",
      "[CV 1/5] END C=10, penalty=None, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=None, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=None, solver=newton-cg;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=None, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=None, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=None, solver=sag;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END ....C=10, penalty=None, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ....C=10, penalty=None, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ....C=10, penalty=None, solver=sag;, score=0.606 total time=   0.2s\n",
      "[CV 5/5] END ....C=10, penalty=None, solver=sag;, score=0.599 total time=   0.2s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=newton-cg;, score=0.609 total time=   0.1s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l2, solver=sag;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END ......C=10, penalty=l2, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ......C=10, penalty=l2, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ......C=10, penalty=l2, solver=sag;, score=0.606 total time=   0.2s\n",
      "[CV 5/5] END ......C=10, penalty=l2, solver=sag;, score=0.599 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, penalty=None, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=None, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=None, solver=newton-cg;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=None, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=None, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END .C=1.0, penalty=None, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END .C=1.0, penalty=None, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END .C=1.0, penalty=None, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END .C=1.0, penalty=None, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END .C=1.0, penalty=None, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ...C=1.0, penalty=None, solver=sag;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END ...C=1.0, penalty=None, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ...C=1.0, penalty=None, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ...C=1.0, penalty=None, solver=sag;, score=0.606 total time=   0.2s\n",
      "[CV 5/5] END ...C=1.0, penalty=None, solver=sag;, score=0.599 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.608 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.598 total time=   0.0s\n",
      "[CV 1/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.608 total time=   0.0s\n",
      "[CV 4/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.598 total time=   0.0s\n",
      "[CV 1/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.605 total time=   0.1s\n",
      "[CV 2/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.601 total time=   0.1s\n",
      "[CV 3/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.608 total time=   0.1s\n",
      "[CV 4/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.606 total time=   0.1s\n",
      "[CV 5/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.598 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=None, solver=sag;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END ...C=0.1, penalty=None, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ...C=0.1, penalty=None, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ...C=0.1, penalty=None, solver=sag;, score=0.606 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, penalty=None, solver=sag;, score=0.599 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.598 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.598 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.601 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.599 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.598 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.609 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.606 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.606 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.599 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, penalty=None, solver=sag;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.01, penalty=None, solver=sag;, score=0.601 total time=   0.2s\n",
      "[CV 3/5] END ..C=0.01, penalty=None, solver=sag;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.01, penalty=None, solver=sag;, score=0.606 total time=   0.2s\n",
      "[CV 5/5] END ..C=0.01, penalty=None, solver=sag;, score=0.599 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.593 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.592 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.593 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.592 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.593 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.592 total time=   0.0s\n",
      "Best model: LogisticRegression(C=10, solver='sag')\n",
      "train f1 score: 0.6034819973544922\n",
      "train precision: 0.614304526228846\n",
      "train recall: 0.6088035714285714\n"
     ]
    }
   ],
   "source": [
    "#Randomized search for logistic regression parameters\n",
    "log_params = {\n",
    "    'solver'      : ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'penalty'     : [None,'l2'],\n",
    "    'C'           : [100, 10, 1.0, 0.1, 0.01],\n",
    "}\n",
    "\n",
    "search_log = RandomizedSearchCV(LogisticRegression(), param_distributions=log_params, n_iter=100, scoring='f1_weighted', verbose=4, random_state=105, refit=True)\n",
    "search_log.fit(x_train_df, y_train)\n",
    "log = search_log.best_estimator_\n",
    "print(f'Best model: {log}')\n",
    "\n",
    "y_pred_train_log = log.predict(x_train_df)\n",
    "log_train_f1 = metrics.f1_score(y_train, y_pred_train_log, average=\"weighted\")\n",
    "log_train_precision = metrics.precision_score(y_train, y_pred_train_log, average=\"weighted\")\n",
    "log_train_recall = metrics.recall_score(y_train, y_pred_train_log, average=\"weighted\")\n",
    "print(f'train f1 score: {log_train_f1}')\n",
    "print(f'train precision: {log_train_precision}')\n",
    "print(f'train recall: {log_train_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation f1 score: 0.6018285954261583\n",
      "validation precision: 0.6168562982072094\n",
      "validation recall: 0.6076666666666667\n"
     ]
    }
   ],
   "source": [
    "#Implement best model on validate set\n",
    "log.fit(x_train_df, y_train)\n",
    "y_pred_log = log.predict(x_val_df)\n",
    "\n",
    "log_validate_f1 = metrics.f1_score(y_val, y_pred_log, average=\"weighted\")\n",
    "log_validate_precision = metrics.precision_score(y_val, y_pred_log, average=\"weighted\")\n",
    "log_validate_recall = metrics.recall_score(y_val, y_pred_log, average=\"weighted\")\n",
    "print(f'validation f1 score: {log_validate_f1}')\n",
    "print(f'validation precision: {log_validate_precision}')\n",
    "print(f'validation recall: {log_validate_recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best model: SVC(gamma=77.42636826811278)\n",
      "train f1 score: 0.6295778659164355\n",
      "train precision: 0.6333656477205505\n",
      "train recall: 0.6312857142857143\n"
     ]
    }
   ],
   "source": [
    "#Randomized search for rbf svm classifier parameters\n",
    "rbfSVM_params = {\n",
    "    \"kernel\" : [\"rbf\"],\n",
    "    \"gamma\" : np.logspace(-3, 8, 10)\n",
    "}\n",
    "\n",
    "search_rbfSVM = RandomizedSearchCV(svm.SVC(), param_distributions=rbfSVM_params, n_iter=100, scoring=\"f1_weighted\", n_jobs=-1, verbose=4, random_state=105)\n",
    "search_rbfSVM.fit(x_train_df, y_train)\n",
    "rbfSVM = search_rbfSVM.best_estimator_\n",
    "print(f'Best model: {rbfSVM}')\n",
    "\n",
    "y_pred_train_rbfsvm = rbfSVM.predict(x_train_df)\n",
    "rbfsvm_train_f1 = metrics.f1_score(y_train, y_pred_train_rbfsvm, average=\"weighted\")\n",
    "rbfsvm_train_precision = metrics.precision_score(y_train, y_pred_train_rbfsvm, average=\"weighted\")\n",
    "rbfsvm_train_recall = metrics.recall_score(y_train, y_pred_train_rbfsvm, average=\"weighted\")\n",
    "print(f'train f1 score: {rbfsvm_train_f1}')\n",
    "print(f'train precision: {rbfsvm_train_precision}')\n",
    "print(f'train recall: {rbfsvm_train_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation f1 score: 0.6068139006814125\n",
      "validation precision: 0.6125852963195944\n",
      "validation recall: 0.6088333333333333\n"
     ]
    }
   ],
   "source": [
    "#Implement best model on validate set\n",
    "rbfSVM.fit(x_train_df, y_train)\n",
    "y_pred_rbfsvm = rbfSVM.predict(x_val_df)\n",
    "\n",
    "rbfsvm_validate_f1 = metrics.f1_score(y_val, y_pred_rbfsvm, average=\"weighted\")\n",
    "rbfsvm_validate_precision = metrics.precision_score(y_val, y_pred_rbfsvm, average=\"weighted\")\n",
    "rbfsvm_validate_recall = metrics.recall_score(y_val, y_pred_rbfsvm, average=\"weighted\")\n",
    "print(f'validation f1 score: {rbfsvm_validate_f1}')\n",
    "print(f'validation precision: {rbfsvm_validate_precision}')\n",
    "print(f'validation recall: {rbfsvm_validate_recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train F1-score</th>\n",
       "      <th>Validation F1-score</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Validation Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.644546</td>\n",
       "      <td>0.624422</td>\n",
       "      <td>0.645120</td>\n",
       "      <td>0.626153</td>\n",
       "      <td>0.644821</td>\n",
       "      <td>0.624833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.603482</td>\n",
       "      <td>0.601829</td>\n",
       "      <td>0.614305</td>\n",
       "      <td>0.616856</td>\n",
       "      <td>0.608804</td>\n",
       "      <td>0.607667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.629578</td>\n",
       "      <td>0.606814</td>\n",
       "      <td>0.633366</td>\n",
       "      <td>0.612585</td>\n",
       "      <td>0.631286</td>\n",
       "      <td>0.608833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train F1-score  Validation F1-score  Train Precision  \\\n",
       "XGBoost                    0.644546             0.624422         0.645120   \n",
       "Logistic Regression        0.603482             0.601829         0.614305   \n",
       "RBF SVM                    0.629578             0.606814         0.633366   \n",
       "\n",
       "                     Validation Precision  Train Recall  Validation Recall  \n",
       "XGBoost                          0.626153      0.644821           0.624833  \n",
       "Logistic Regression              0.616856      0.608804           0.607667  \n",
       "RBF SVM                          0.612585      0.631286           0.608833  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    'Train F1-score': [xgb_train_f1, log_train_f1, rbfsvm_train_f1],\n",
    "    'Validation F1-score': [xgb_validate_f1, log_validate_f1, rbfsvm_validate_f1],\n",
    "    'Train Precision': [xgb_train_precision, log_train_precision, rbfsvm_train_precision],\n",
    "    'Validation Precision': [xgb_validate_precision, log_validate_precision, rbfsvm_validate_precision],\n",
    "    'Train Recall': [xgb_train_recall, log_train_recall, rbfsvm_train_recall],\n",
    "    'Validation Recall': [xgb_validate_recall, log_validate_recall, rbfsvm_validate_recall]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results, index=['XGBoost', 'Logistic Regression', 'RBF SVM'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1 score: 0.6670612954517966\n",
      "test precision: 0.6672497191812925\n",
      "test recall: 0.6671666666666667\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(x_test_df, y_test)\n",
    "y_pred_xgb_test = xgb.predict(x_test_df)\n",
    "\n",
    "xgb_test_f1 = metrics.f1_score(y_test, y_pred_xgb_test, average=\"weighted\")\n",
    "xgb_test_precision = metrics.precision_score(y_test, y_pred_xgb_test, average=\"weighted\")\n",
    "xgb_test_recall = metrics.recall_score(y_test, y_pred_xgb_test, average=\"weighted\")\n",
    "print(f'test f1 score: {xgb_test_f1}')\n",
    "print(f'test precision: {xgb_test_precision}')\n",
    "print(f'test recall: {xgb_test_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No delay       0.64      0.59      0.61      6089\n",
      "       Delay       0.61      0.66      0.63      5911\n",
      "\n",
      "    accuracy                           0.62     12000\n",
      "   macro avg       0.63      0.63      0.62     12000\n",
      "weighted avg       0.63      0.62      0.62     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_val = classification_report(y_val, y_pred_xgb, labels=[0,1], target_names=[\"No delay\", \"Delay\"])\n",
    "print(report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No delay       0.66      0.68      0.67      6039\n",
      "       Delay       0.67      0.65      0.66      5961\n",
      "\n",
      "    accuracy                           0.67     12000\n",
      "   macro avg       0.67      0.67      0.67     12000\n",
      "weighted avg       0.67      0.67      0.67     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_test = classification_report(y_test, y_pred_xgb_test, labels=[0,1], target_names=[\"No delay\", \"Delay\"])\n",
    "print(report_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c096d0d5268e44db3ad3979eb53dfd42764b967015cef5dd9d12a25a4c4482d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
